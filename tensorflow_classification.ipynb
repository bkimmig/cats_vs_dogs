{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "import copy\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opening the Images\n",
    "\n",
    "Since we cannot open all of the images at one time, we will need a quick method to help us open the images in 'batches'. Below, I have written a function to easily open images and resize them to the specified shape. The function below will also return the label of the image - whether it is a cat (1) or a dog (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_images(image_list, path='', shape=(50, 50), return_labels=False):\n",
    "    \"\"\"\n",
    "    Open a list of images, resize them all to a specified shape.\n",
    "    This will also return the 'label' of the \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image_list: list\n",
    "    path: string\n",
    "    shape: tuple\n",
    "    return_labels: bool, default is False\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    images: np.array\n",
    "    labels: (optional)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    for fname in image_list:\n",
    "        if 'cat' in fname:\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)    \n",
    "        img = Image.open(os.path.join(path, fname))\n",
    "        img = img.resize((shape[0], shape[1]), Image.ANTIALIAS)\n",
    "        smpl_img = np.asarray(img)\n",
    "        images.append(smpl_img)\n",
    "    \n",
    "    labels = np.array(labels)\n",
    "    cats = labels == 1\n",
    "    dogs = labels == 0\n",
    "    labels = np.array(np.stack((cats, dogs), axis=1), dtype=int)\n",
    "    if return_labels:\n",
    "        return np.array(images), labels\n",
    "    else:\n",
    "        return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batching\n",
    "\n",
    "We need a method for getting images from the list in 'batches' since we cannot open all of the images at one time. Below I have created a simple method to help us with that. It takes the full image list and returns a uniformly chosen random set of image names from the list. You can specify the size of the batch in the call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class Batch:\n",
    "#     \"\"\"\n",
    "#     Get a uniformly random selection of your list, with a specified size.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, image_list, batch_size=128):\n",
    "#         self.i = 0\n",
    "#         self.n = len(image_list)\n",
    "#         self.image_list = image_list\n",
    "#         self.batch_size = batch_size\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         return self\n",
    "    \n",
    "#     def next(self):\n",
    "#         idxs = np.random.randint(0, len(self.image_list), size=self.batch_size)\n",
    "#         return self.image_list[idxs]\n",
    "    \n",
    "class Batch:\n",
    "    \"\"\"\n",
    "    Get a uniformly random selection of your list, with a specified size.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_list, batch_size=128):\n",
    "        self.n = len(image_list)\n",
    "        self.image_list = image_list\n",
    "        self.batch_size = batch_size\n",
    "        self.indexes = np.arange(self.n)\n",
    "        self.probs = np.ones(self.n)/self.n\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def reset_probabilities(self):\n",
    "        self.probs = np.ones(self.n)*(1/self.n)\n",
    "    \n",
    "    def update_probabilities(self, idx):\n",
    "        self.probs[idx] = 0.0\n",
    "        zero_prob_mask = (self.probs == 0.0)\n",
    "        self.probs = np.ones(self.n)/np.sum(np.invert(zero_prob_mask))\n",
    "        self.probs[zero_prob_mask] = 0.0\n",
    "        return\n",
    "    \n",
    "    def next(self):\n",
    "        pmask = self.probs > 0.0\n",
    "        if np.sum(pmask) >= self.batch_size:\n",
    "            idxs = np.random.choice(\n",
    "                self.indexes, \n",
    "                size=self.batch_size, \n",
    "                replace=False, \n",
    "                p=self.probs)\n",
    "        else:\n",
    "            self.reset_probabilities()\n",
    "            idxs = np.random.choice(\n",
    "                self.indexes, \n",
    "                size=self.batch_size, \n",
    "                replace=False, \n",
    "                p=self.probs)\n",
    "        self.update_probabilities(idxs)\n",
    "        return self.image_list[idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permuting (flipping) Images\n",
    "\n",
    "To artificially increase the size of the training image set, we can permute the images in the dataset by flipping or rotating the images, increasing their contrast or brightness. For this I will write a function that randomly flips random images in the training data. This will be done a few times for each batch. The flipped images will be chosen uniformly at random from the current training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_images(inputs, flip_sample_size=0.5):\n",
    "    \"\"\"\n",
    "    Uniformly at random flip a fraction of the images.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    inputs: np.array\n",
    "        vector of images\n",
    "    flip_sample_size: float\n",
    "        fraction of images to flip - (0., 1.].\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    inputs: np.array\n",
    "        vector of images with random sample flipped.\n",
    "    \"\"\"\n",
    "    inputs = copy.deepcopy(inputs)\n",
    "    n_images = inputs.shape[0]\n",
    "    flip_size = int(np.round(flip_sample_size*n_images))\n",
    "    idx = np.random.choice(np.arange(n_images), size=flip_size, replace=False)\n",
    "    inputs[idx] = np.fliplr(inputs[idx])\n",
    "    return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow: A Convolutional Neural Network\n",
    "\n",
    "The majority of this code is referenced from the tutorial on the TensorFlow website about <a href='https://www.tensorflow.org/get_started/mnist/pros'> convolutional neural networks </a>.\n",
    "\n",
    "Convolutional neural networks are nice for images as they allow you to reduce the number of coefficients for each layer. In a fully connected neural network you can get weight layers that can be huge, in a convolutional neural network your weight layers are much smaller. Arguably, this gives you fewer places to get lost because there are much fewer coefficients.\n",
    "\n",
    "\n",
    "## 2D Convolution\n",
    "\n",
    "We need a basic function to perform the 2 dimensional convolution. This convolves image the weights and adds the bias. There is also a stride option, where you can change how much the convolutional filter moves, for this we use 1 pixel. Finally it puts this through the activation function (relu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    \"\"\"\n",
    "    Performs the 2d convolution, adds the bias and does the relu.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: tf.placeholder\n",
    "    W: tf.variable\n",
    "    b: tf.variable\n",
    "    strides: int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x: tf.placeholder\n",
    "        convolution with layer weights and bias added\n",
    "    \"\"\"\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding=\"SAME\")\n",
    "    return tf.nn.relu(x + b) ## add the bias and take the relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Maxpool\n",
    "\n",
    "After convolution we need to do some pooling. Pooling can reduce the size of the convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    \"\"\"\n",
    "    Pool the data after it has been convolved. This will downsample the\n",
    "    image by k. If k is 2 then a 28x28 will be a 14x14 image.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: tf.placeholder\n",
    "    k: int\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x: tf.placeholder\n",
    "        convolution layer\n",
    "    \"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], \n",
    "                              strides=[1, k, k, 1],\n",
    "                              padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "Finally we need to put the pieces above together to create our CNN. For this classification we will have 4 convolutional layers, that will go into a fully connected layer and be used to get the precdiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(x, W, b, dropout):\n",
    "    \"\"\"\n",
    "    The convolutional neural network. Takes your data, weights, biases\n",
    "    and dropout. All of these need to be TensorFlow variables or\n",
    "    placeholders. To avoid have a bunch of arguments, pass the weights\n",
    "    and biases for each layer in in dictionaries with keys\n",
    "    \n",
    "    0 - first layer\n",
    "    1 - second layer\n",
    "    .\n",
    "    .\n",
    "    .\n",
    "    fc - full connected layer\n",
    "    out - output layer\n",
    "    parity_out - parity output layer (odd/even label)\n",
    "    \n",
    "    This function will alter the final layer to allow us to predict the\n",
    "    oddness/evenness (parity) of the integer. I will also keep the integer\n",
    "    classification to train on, then with little training we can use\n",
    "    the upstream layers to predict the parity. We can then just later \n",
    "    optimize on the finaly 'parity_out' layer to get the classification\n",
    "    for odd or even.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : tf.placeholder\n",
    "    W : dictionary of tf.variables (keys above)\n",
    "    b : dictionary of tf.variables (keys above)\n",
    "    dropout: tf.placeholder\n",
    "    img_shape: tuple\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pred: tf method to get the predicitons for the digit.\n",
    "    parity_pred: tf method to get the predicitons for the parity. \n",
    "    \"\"\"\n",
    "    \n",
    "    ## convolve and pool for the first layer, downsample by 2\n",
    "    conv1 = conv2d(x, W['0'], b['0'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    ## convolve and pool for the second layer, downsample by 2\n",
    "    conv2 = conv2d(conv1, W['1'], b['1'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    ## convolve and pool for the third layer, downsample by 2\n",
    "    conv3 = conv2d(conv2, W['2'], b['2'])\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "    \n",
    "    ## convolve and pool for the third layer, downsample by 2\n",
    "    conv4 = conv2d(conv3, W['3'], b['3'])\n",
    "    conv4 = maxpool2d(conv4, k=2)\n",
    "\n",
    "    ## create the fully connected layer, and reshape the \n",
    "    ## second conv layer\n",
    "    fc = tf.reshape(conv4, [-1, W['fc'].get_shape().as_list()[0]])\n",
    "    fc = tf.add(tf.matmul(fc, W['fc']), b['fc'])\n",
    "    fc = tf.nn.relu(fc)\n",
    "    \n",
    "    ## apply the dropout\n",
    "    fc = tf.nn.dropout(fc, dropout)\n",
    "    \n",
    "    ## evaluate the final layer that gives the prediction for the class\n",
    "    pred = tf.matmul(fc, W['out']) + b['out']\n",
    "    \n",
    "    return {'pred': pred, \"conv1\": conv1, \"conv2\": conv2, \"conv3\": conv3, \"conv4\": conv4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "### Learning Rate\n",
    "\n",
    "This is very important and will most likely need to be messed with. I have found 0.1 to work well with other data sets.\n",
    "\n",
    "### Training Iterations\n",
    "\n",
    "Specify the number of training iterations, the more we do the more the training accuracy will increase.\n",
    "\n",
    "### Second Training Iterations\n",
    "\n",
    "I will train mulitple times on the same batch, but will also do random perumations of the images in the second training session. This parameter specifies the number of times you want to re-train, with permutations, on the same batch.\n",
    "\n",
    "### Batch Size\n",
    "\n",
    "This can be messed with but typically I have found around 100 to be pretty good.\n",
    "\n",
    "### Image Shape\n",
    "\n",
    "The size of the images when resizing them to a constant size (upon opening).\n",
    "\n",
    "### Number of Labels\n",
    "\n",
    "The number of classes you will be labeling. In this case it is binary as we are labeling an image as either a cat or a dog.\n",
    "\n",
    "### Dropout\n",
    "\n",
    "Prevents overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "train_iter = 10000\n",
    "second_train_iter = 5\n",
    "batch_size = 100\n",
    "\n",
    "img_shape = (64, 64)\n",
    "# img_shape = (50, 50)\n",
    "n_labels = 2\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholders\n",
    "\n",
    "We need TensorFlow placeholders for the images and the labels. These are a specified type and shape. For instance we know the shape of the images but we don't know how many there will be. So we have the shape [None (number of images, image height, image width, and number of channels]. \n",
    "\n",
    "Then we create a placeholder for the labels. Which is the number of images by the number of labels (2).\n",
    "\n",
    "The keep probability is also known as the dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## placeholders\n",
    "x = tf.placeholder(tf.float32, [None, img_shape[0], img_shape[1], 3])\n",
    "y = tf.placeholder(tf.float32, [None, n_labels])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables\n",
    "\n",
    "Finally we need some variables for the items in the layers, the weights and biases. Here I have some dictionaries of the layers with keys corresponding to the layers. The numbers correspond to the layer, 'fc' is the fully connected layer and 'out' is the layer that will contain the labels.\n",
    "\n",
    "Then the biases have the shapes of the last dimension in each layer.\n",
    "\n",
    "When the image size is 120 you need a fully connected layer that is 8*8*256 or \n",
    "\n",
    "Should be $\\frac{image_{shape}[0]}{2^{number \\ of \\ layers}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weights = {\n",
    "#     # 3x3 conv, 3 (rgb) input, 32 'channels' output\n",
    "#     '0': tf.Variable(tf.random_normal([3, 3, 3, 32])),\n",
    "#     '1': tf.Variable(tf.random_normal([3, 3, 32, 64])),\n",
    "#     '2': tf.Variable(tf.random_normal([3, 3, 64, 128])),\n",
    "#     '3': tf.Variable(tf.random_normal([3, 3, 128, 256])),\n",
    "#     'fc': tf.Variable(tf.random_normal([4*4*256, 1024])),\n",
    "#     'out': tf.Variable(tf.random_normal([1024, n_labels]))\n",
    "# }\n",
    "\n",
    "weights = {\n",
    "    # 3x3 conv, 3 (rgb) input, 32 'channels' output\n",
    "    '0': tf.Variable(tf.random_normal([5, 5, 3, 32])),\n",
    "    '1': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    '2': tf.Variable(tf.random_normal([5, 5, 64, 128])),\n",
    "    '3': tf.Variable(tf.random_normal([5, 5, 128, 256])),\n",
    "    'fc': tf.Variable(tf.random_normal([4*4*256, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_labels]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    '0': tf.Variable(tf.random_normal([32])),\n",
    "    '1': tf.Variable(tf.random_normal([64])),\n",
    "    '2': tf.Variable(tf.random_normal([128])),\n",
    "    '3': tf.Variable(tf.random_normal([256])),\n",
    "    'fc': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_labels])),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network Model\n",
    "\n",
    "Set up the 'cnn' function with your placeholders and variables. Then define the cost function and pick the appropriate optimizer, I found the Adam Optimizer to be popular in many tutorials. Then define a method for looking at your training accuracy.\n",
    "\n",
    "Finally, we need a function to get the labels out. The pred will return the probabilities for each label, so we just take the argmax of each set of labels (e.g. [0.3, 0.7] or some numbers, not necessarily between 0 and 1) to determine whether it is a cat or dog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Construct model\n",
    "cnn_model = cnn_model_fn(x, weights, biases, keep_prob)\n",
    "pred = cnn_model['pred']\n",
    "\n",
    "## Define loss and optimizer \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "## functions to get the labels out\n",
    "ypred = tf.argmax(pred, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training!!!\n",
    "\n",
    "In the second training session on the batch randomly flip 20% of the images.\n",
    "\n",
    "\n",
    "call the optimizer function. This knows about the functions up-\n",
    "stream and will update variables we just need to pass in the \n",
    "placeholders or in this case training data and dropout\n",
    "this is where the training happens. All weights and biases are updated here.\n",
    "\n",
    "sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "\n",
    "Try: training on the same batch multiple times...\n",
    "\n",
    "Set learning rate lower..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_path = 'data/train/'\n",
    "image_list = np.array(os.listdir(train_path))\n",
    "\n",
    "train_image_list = image_list[:-500]\n",
    "test_image_list = image_list[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch = Batch(train_image_list, batch_size)\n",
    "\n",
    "step = 1\n",
    "while step*batch_size < train_iter:\n",
    "    ## get a batch of data -- use built in next function\n",
    "    batch_img_names = batch.next()\n",
    "    \n",
    "    batch_x, batch_y = open_images(batch_img_names, path=train_path, shape=img_shape, return_labels=True)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "    \n",
    "    for i in range(second_train_iter):\n",
    "        inputs = flip_images(batch_x, flip_sample_size=0.4)\n",
    "        sess.run(optimizer, feed_dict={x: inputs, y: batch_y, keep_prob: dropout})\n",
    "    \n",
    "    ## print the accuracy mod 10 steps\n",
    "    if step % 10 == 0:\n",
    "        acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "        print(\"Iteration : {}, Training Accuracy: {}\".format(step*batch_size, acc))\n",
    "    \n",
    "    step += 1\n",
    "\n",
    "acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "print(\"Iteration : {}, Training Accuracy: {}\".format(step*batch_size, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_x, test_y = open_images(test_image_list, path=test_path, shape=img_shape, return_labels=True)\n",
    "\n",
    "acc = sess.run(accuracy, feed_dict={x: test_x, y:test_y, keep_prob: dropout})\n",
    "print(\"Testing Accuracy: {}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
